{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735971b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "import chromadb\n",
    "import ollama\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c0c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"D:/HRAgent/Policies/ANTI-BRIBERY AND ANTI-CORRUPTION POLICY OF TATA INDUSTRIES.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a7e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e173443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultantpdf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9be097",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultantpdf.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f8db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://172.16.0.178:8010\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4bfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=OllamaEmbeddings(model=\"llama3.2:1b\",base_url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c03029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "semanticchunker=SemanticChunker(embedding, breakpoint_threshold_type=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4481d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 14024.42it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks=semanticchunker.create_documents([doc.page_content for doc in tqdm(resultantpdf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7af7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=embedding, \n",
    "    persist_directory=\"knowledgebase\", \n",
    "    collection_name=\"llama_embed_knolwdge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83184e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdityaKumarSingh\\AppData\\Local\\Temp\\ipykernel_12312\\4032791689.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chroma_db.as_retriever().get_relevant_documents(\"finance vice persident of tata insights and quants\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='3. In case of violations of this ABAC policy, the Compliance Officer  shall  take \\nappropriate steps such as: \\na) Assigning an Investigation Team : Experts with the right knowledge and \\nobjectivity may be appointed to investigate a complaint. b) Conducting an Investigation : Every investigation  relating to a suspected \\nviolation of this ABAC Policy shall  be investigated by the Compliance Officer  \\ntogether with other members assigned under sub -clause (a) above. The \\nobjective of such a n investigation would be to determine the facts, through \\ninterviews with concerned participants and/or review of documents . Such \\ninvestigation team will make a written demand for information, records etc .'),\n",
       " Document(metadata={}, page_content='Appropriate due diligence is conducted and properly documented; \\nb. Formal commitment (in writing) is sought from the third party to ensure \\ncompliance to these standards; '),\n",
       " Document(metadata={}, page_content='Usually, two people are involved and both w ould benefit. Examples of a '),\n",
       " Document(metadata={}, page_content='Under no circumstances should any Designated Persons ever solicit a gift from any \\nperson or company that is doing, or seeks to do, business with the Company. Note ')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db.as_retriever().get_relevant_documents(\"finance vice persident of tata insights and quants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fd19c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you do not know the answer, please think rationally and answer from your own knowledge base.\n",
    "Don't put extra information\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb27789",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(base_url=url,model=\"llama3.2:1b\",temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75cacacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"finance vp of tata iq?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab24b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdityaKumarSingh\\AppData\\Local\\Temp\\ipykernel_12312\\2838688471.py:8: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa_chain.run(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'S Sriram is the Vice President (Finance) & Company Secretary.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", \n",
    "    retriever=chroma_db.as_retriever(), \n",
    "    chain_type_kwargs=chain_type_kwargs)\n",
    "\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b65435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdityaKumarSingh\\.conda\\envs\\yolov8\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3442: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "709a35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6028d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOllama(base_url=\"http://172.16.0.178:8010/\",model=\"llama3.2:1b\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "872be2e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ChatOllama.with_structured_output() missing 1 required positional argument: 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGradeDocument\u001b[39;00m(BaseModel):\n\u001b[0;32m      2\u001b[0m     binary_score: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive a binary score \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m score to indicate whether the document is relevant or not\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m structure_llm_grader\u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: ChatOllama.with_structured_output() missing 1 required positional argument: 'schema'"
     ]
    }
   ],
   "source": [
    "class GradeDocument(BaseModel):\n",
    "    binary_score: str= Field(\"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant or not\")\n",
    "\n",
    "structure_llm_grader= llm.with_structured_output(GradeDocument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "585ddce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system=\"\"\" You are a grader assessing relevance of a retrieved document to a user question.\\n\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as a relevent.\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant or not\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82f250b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_prompt= ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system),\n",
    "    (\"human\",\"\"\"Retrieved documents: \\n\\n {documents} \\n\\n user_question: {question}\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2675d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=chroma_db.as_retriever().get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "addae782",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_grader=grade_prompt|structure_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a45393dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I would grade this document as \"No\" because it does not contain any keyword(s) or semantic meaning related to a finance VP of Tata IQ.\\n\\nThe document is about compliance officer designations and responsibilities, which are more relevant to companies in general. The mention of \"ABAC Policy\" and \"Designated Persons\" suggests that the company may be involved in regulatory or compliance-related activities, but it does not specifically mention Tata IQ.\\n\\nTherefore, I would give a binary score \\'no\\' for relevance.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-01-19T17:15:40.021132207Z', 'done': True, 'done_reason': 'stop', 'total_duration': 33854453017, 'load_duration': 27475757, 'prompt_eval_count': 184, 'prompt_eval_duration': 8159888000, 'eval_count': 102, 'eval_duration': 25664023000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-fa4afb89-8eb1-4c49-9932-63196e5c2595-0', usage_metadata={'input_tokens': 184, 'output_tokens': 102, 'total_tokens': 286})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_grader.invoke({\"question\":query,\"documents\":doc[0].page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166eecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "yolov8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
